# GM-Kit Feature Prompts and Tasks (Arcane Library Edition)

The following epics contain features or tasks.  

- Features are implemented using spec-kit as a formal process.  The verbage for a feature will be used as the initial `/speckit.specify` prompt to translate the feature into executable specs. Prompts are grouped and ordered by those epics so the workflow remains: prompts → specs → plans → tasks → implementation.

- Tasks are items listed in an epic that don't require a formal spec.  These tasks are managed directly by the user instructing the coding assistant and usually involve revisions to the project itself rather than new features.  Examples of tasks are updating user/team documentation, revising context for the coding assistant, restructring project folders and files, some smaller code refactoring, etc. 

---

## ✅ Epic 1 — Repository Setup & Governance **[COMPLETED]**

### ✅ E1-01. Repo Bootstrap (README + .gitignore + Structure Audit) **[FEATURE, COMPLETED]**
Feature description:
Scaffold a minimal README describing GM-Kit’s Arcane Library mission, add a `.gitignore` that excludes `temp-resources/` and `spec-kit/`, and then audit the folder structure and included files to verify the project is ready to push to gihtub. Include instructions for keeping the README synced with planning docs.

Success looks like: a repo that is ready for PRs, ignores transient analysis folders and is ready for python development.

### ✅ E1-02. Development Lifecycle Documentation **[FEATURE, COMPLETED]**
Feature description:
Add contributor documentation that explains the enforced workflow: todos (as epics) → prompts → specs → /plan → tasks → implementation → validation. Highlight how prompts are stored, how specs reference planning artifacts, and where status lives. Include guidance for capturing decisions in Obsidian and syncing back.

Success looks like: anyone can trace a shipped change back to the originating todo epic.

### ⚠️ E1-03. Testing Strategy (Deferred) **[FEATURE, DEFERRED]**
Feature description:
Define how to unit or integration test the MCP. Cover minimal walking tests (CLI dry runs, mock agents) and outline where automated scripts live. Specify pass/fail gates that block shipping (e.g., failing CLI smoke test).

Success looks like: a practical testing rubric the team can run locally before each PR.

## Epic 2 — Development Environment & Walking Skeleton

### ✅ E2-01. Knowledge-Graph MCP Experiment (Optional) **[FEATURE, COMPLETED]**
Feature description:
Spec an experiment that wires a knowledge-graph MCP into the workflow to compare against vendor-provided session distillers. Outline evaluation metrics and fallback plans if the integration adds friction.

Success looks like: documented learnings on whether the knowledge graph improves Arcane Library outputs.

NOTE: The developer will install the mcp and configure it. Use the context at this link in both codex and opencode to ensure it's working correctly: https://github.com/modelcontextprotocol/servers/tree/main/src/memory (See SYSTEM PROMPT section in the readme, note we are using Cheezy's recommended knowledge graph mcp rather than the Memory mcp)

### E2-02. Installation and Walking Skeleton **[FEATURE, NOT SPECCED]**
Feature description:
1) Deliver a Python/uv installer that installs the following three artifacts:

For macOS/Linux (using $HOME):
    a) Create and populate the $HOME/.local/share/uv/tools/gmkit-cli/lib/python*/site-packages/gmkit_cli/ subfolder. The gmkit_cli subfolder is a package directory with __init__.py and other modules, not a single .py file.
    b) Install ```gmkit``` python file (without the .py extension) to ```$HOME/.local/share/uv/tools/gmkit-cli/bin/gmkit```. This is a short python file (with shebang, no .py extension) that wraps the logic in $HOME/.local/share/uv/tools/gmkit-cli/lib/python*/site-packages/gmkit_cli/.
    c) Create a symlink in $HOME/.local/bin/gmkit that points to ```gmkit``` under ```$HOME/.local/share/uv/tools/gmkit-cli/bin/gmkit```.
        ```$HOME/.local/bin/gmkit -> $HOME/.local/share/uv/tools/gmkit-cli/bin/gmkit```
        i.  This allows the command to be invoked from anywhere as $HOME/.local/bin is included in the OS PATH.

For Windows, mirror the same artifacts in uv’s tool layout:
    a) Create and populate %LOCALAPPDATA%\uv\tools\gmkit-cli\Lib\site-packages\gmkit_cli\ (package directory with __init__.py and other modules).
    b) Install the entrypoint to %LOCALAPPDATA%\uv\tools\gmkit-cli\Scripts\gmkit.exe (or gmkit shim if uv emits one without extension); this wraps the logic in the Lib\site-packages\gmkit_cli\ folder. This .exe is generated by uv when the tool is installed.
    c) Create a shim at %USERPROFILE%\.local\bin\gmkit.cmd (preferred) that forwards to %LOCALAPPDATA%\uv\tools\gmkit-cli\Scripts\gmkit.exe, ensuring %USERPROFILE%\.local\bin is on PATH. If symlinks are available, a symlink is acceptable; if PowerShell is preferred, use gmkit.ps1. If the environment prefers WindowsApps or another PATH location, note that alternative but default to %USERPROFILE%\.local\bin.
        ```%USERPROFILE%\.local\bin\gmkit.cmd -> %LOCALAPPDATA%\uv\tools\gmkit-cli\Scripts\gmkit.exe```
        Example gmkit.cmd contents:
        ```bat
        @echo off
        "%LOCALAPPDATA%\uv\tools\gmkit-cli\Scripts\gmkit.exe" %*
        ```

2) This allows the user to invoke the python "gmkit" command (from a terminal) along with a subcommand "init" which takes three inputs: a) required path to temp folder for writing scripts/prompts, b) optional coding agent type (claude, codex-cli, gemini, qwen), c) optional target OS (windows for PowerShell or macos/linux for bash). If optional parameters are not provided, the Python script prompts the user to select them.

This will install the following folders and logic into the project folder (based on the OS and coding agent selected):

    - <project folder>/<agent folder>/prompts/ (or commands/, or similar): 
        - each coding agent has a different location for the prompts:
            - for claude the location is ```<project folder>/.claude/command```
            - for codex-cli the location is ```<project folder>/.codex-cli/prompts```
            - for gemini the location is ```<project folder>/.gemini/command```
            - for qwen the location is ```<project folder>/.qwen/prompts```
        - the prompt files: are the specific slash commands invoked inside the coding agent.  The first and only prompt markdown file installed by ```gmkit init``` for this feature is:
            - gmkit.hello-gmkit.md
    - <project folder>/.gmkit/memory/  (use `.gmkit` consistently across platforms)
        - constitution.md (contains the core principles the agent is supposed follow when creating TTRPG game master artifacts).
    - <project folder>/.gmkit/scripts/<bash or ps>/ (invoked by the agent on behalf of the /slash command/prompts listed above). 
        - say-hello.sh
    <project folder>/.gmkit/templates (simple template files that are populated with the arguments provided by the script files above).
        - hello-gmkit-template.md

3) Once the project folder has been initialized, the user can then launch his agent of choice and issue the /gmkit.hello-gmkit slash command, passing in a greeting such as "Hello from <Agent>!". This will cause the agent to read and act on behalf of the gmkit.hello-gmkit.md prompt content along with any user provided greeting. This will trigger the following events:
    - The agent will follow the instructions in the gmkit.hello-gmkit.md file to generate the argument list required to invoke the say-hello.sh file passing in the greeting from the user along with a greeting file sequence number.  The agent should determine the latest sequence number by evaluating the "<project folder>/greetings/greetingXX.md" files and looking for the highest sequence number and then incrementing that number by 1.
    - The script execution will fill in the template, replacing variables in the template with the argument list (in this case the single greeting message argument and the sequence number).
    - The script will write the contents of the greeting to the chat window and also write the contents to the markdown file path as "<project folder>/greetings/greetingXX.md", where XX is the numeric sequence number argument.

Non-functional requirements (must be explicit in spec):
    - gmkit init is safe to re-run and idempotent for existing folders/files (no destructive overwrites without clear user intent).
    - Script/template output is deterministic for the same inputs.
    - Clear, actionable error messages for missing paths/permissions.
    - No network access required after installation for hello-gmkit flow.

Out of scope (must be explicit in spec):
    - No real content generation beyond the minimal hello-gmkit scaffolding.
    - hello-gmkit is a temporary walking-skeleton command and will be removed once real commands exist.

Documentation must cover (include in spec and docs):
    - How a new slash command maps to its prompt/script/template artifacts and output path.
    - Campaign flow example: `/gmkit.campaign` installs prompt + script + template, and creates `<project folder>/campaigns/<campaign_name>/campaign_notes.md`.
    - Scenario flow example: `/gmkit.scenario` creates `<project folder>/campaigns/<campaign_name>/scenarios/<scenario_name>/scenario_notes.md`.
    - Two creation patterns: (1) create new folder/file outputs, (2) append a new section inside an existing notes file (e.g., `/gmkit.npc`, `/gmkit.encounter`, `/gmkit.reward` inside scenario notes).
    - Users can create multiple campaigns per project and multiple scenarios per campaign.

Success looks like: 

- contributors can install once with uv,
    - proven by integration tests that will 1) remove the gmkit-cli installation (if it's there) and then install it cleanly. The test will then verify the essential folders and files are present in the installation folder.
- contributors can run "gmkit init" from terminal (with required temp path and optional agent/OS params) have scripts/prompts copied to temp workspace for /gmkit.hello-gmkit
    - proven by tests verifying files in temp workspace, plus documentation on extending the skeleton.
- contributors can invoke /gmkit.hello-gmkit slash command from their coding agent choice of choice (selected during "gmkit init" command) and the "<project folder>/greetings/greetingXX.md" file will be written with the appropriate XX sequence number.
    - proven by tests that invoke the script directly to fill the template and verify the "<project folder>/greetings/greetingXX.md" file has been written; optional: verify agent batch mode if supported. For Gemini CLI, use headless mode with a slash-prefixed prompt (e.g., `gemini --prompt "/gmkit.hello-gmkit Hello from Gemini!"`) rather than `gemini gmkit.hello-gmkit`.

### E2-03. CI/CD Pipeline for Walking Skeleton **[FEATURE, NOT SPECCED]**
Feature description:
Establish a CI/CD pipeline that validates the walking skeleton implementation (E2-02). The pipeline must run quality gates including lint/format/type-check, unit tests for installer functionality, and integration tests for the gmkit init and hello-gmkit workflows. Define release/versioning, tagging, and changelog steps for the walking skeleton. Include a release checklist (artifacts, docs, installation verification) and how feedback is collected.

Requirements:
- Unit tests covering installer components (folder creation, script generation, symlink creation)
- Integration tests for `gmkit init` command across supported agents (claude, codex-cli, gemini, qwen)
- Integration tests for `/gmkit.hello-gmkit` slash command execution and template rendering
- Cross-platform testing (macOS/Linux/Windows) for installer artifacts
- Pipeline runs on each PR to main branch
- Automated artifact generation for releases

Success looks like: a passing CI/CD pipeline that validates the walking skeleton functionality, provides repeatable release process, and ensures cross-platform compatibility of the installer and hello-gmkit workflow.

---

## Epic 3 — Spec-Kit Architecture Analysis

### E3-01. Spec-Kit Repo Deep Dive
Feature description:
Download the upstream spec-kit repo and catalogue how commands, templates, and scripts are organized. Include notes on versioning, template prefixes, and how prompts feed specs.

Success looks like: a concise reference document stored in `planning/` that captures the structural learnings.

### E3-02. Constitution → Gate Mapping
Feature description:
Trace how Spec-Kit’s constitution articles produce gates like the “Simplicity Gate” and “Anti-Abstraction Gate.” Clarify what “No future-proofing” truly enforces and how those checks can be adapted for GM-Kit.

Success looks like: actionable guidance for crafting GM-Kit checklists based on upstream doctrine.

### E3-03. MCP Flow Walkthrough (Specify → Clarify → Plan → Execute)
Feature description:
Describe, with screenshots or transcripts, how each Spec-Kit phase behaves today when building a feature. Focus on checklists, clarifying questions, and artifact outputs so we can mirror or adapt them.

Success looks like: the team can answer “why does Spec-Kit ask for this gate?” with evidence.

### E3-04. Guardrails & Cross-Platform Considerations
Feature description:
Identify what guardrails are necessary when GM-Kit becomes its own MCP: how to ensure cross-platform CLI compatibility, how to warn about licensed content, and how to steer AI agents away from unsafe behaviors.

Success looks like: a list of guardrails ready to be codified into specs and templates.

---

## Epic 4 — PDF → Markdown Research & Pipelines

### E4-01. Research Plan Across Three Module Formats
Feature description:
Define the research matrix: DMsGuild two-column, Call of Cthulhu, and Werewolf 5E samples. Outline success criteria, manual review steps, and how findings will be recorded.

Success looks like: a reproducible study plan for evaluating conversion quality across systems.

### E4-02. AI-Only Conversion Approach
Feature description:
Prompt AI to perform direct conversion of PDFs into Markdown, describing how to manage context limits, heading detection, call-out handling (`>` for box text), and verification loops with the user.

Success looks like: documented steps for when AI alone is sufficient and how to check results.

### E4-03. CLI/Python Conversion Pipeline
Feature description:
Design the hybrid workflow: CLI utilities (`pdfinfo`, `qpdf`, `pdftohtml`, `pandoc`, `pdfimages`, `ocrmypdf`) vs pure-Python alternatives. Include install guidance for Windows/macOS/Linux and show where AI should clean up the Markdown output.

Success looks like: a spec-ready blueprint for automating conversions portably.

### E4-04. Heading & Hierarchy Verification Tooling
Feature description:
Create a command that surfaces title snippets from the PDF, allows the AI/user to assign heading levels, and validates whether the Markdown mirrors the PDF’s hierarchy.

Success looks like: fewer mis-leveled headers and a repeatable QA checklist.

### E4-05. Box Text & Callout Handling
Feature description:
Define how boxed text should appear in Markdown (`>`), how to tag read-aloud vs GM-only notes, and how to preserve their placement relative to body copy.

Success looks like: readable Markdown that keeps the intent of boxed callouts intact.

### E4-06. Version 2 Image Extraction
Feature description:
Plan the follow-up feature that extracts images, saves them to `images/`, and injects relative links into the Markdown at the correct positions. Include licensing cautions.

Success looks like: a scoped V2 plan that can follow the initial converter work.

### E4-07. PDF→Markdown Feature

Feature description:

Ship a slash-command-driven PDF→Markdown flow usable from all supported agents (claude, codex-cli, gemini, qwen). The flow: (1) split large PDFs into chunk PDFs via `qpdf` (preferred) or `pdftk` using bash/PowerShell scripts; (2) convert each chunk to Markdown; (3) merge chunk Markdown into a single file. The installer installs and verifies `qpdf` (preferred) or `pdftk` via system package managers (brew/apt/choco/winget). If no package manager is available, allow bundling a vetted qpdf binary when licensing permits. No Python splitter fallback for MVP. Capture dependencies, CLI surface, acceptance tests, and integration with Arcane Library formatting work.

Success looks like: a locked-in scope for the converter with chunk/convert/merge implemented via CLI tools, agent-accessible prompts, and verified PDF processing tools.

---

## Epic 5 — Prompt & Schema Overhaul (Arcane Library)

### E5-01. Arcane Library Schema Definition
Feature description:
Spec the authoritative schema for Synopsis, Background, Word to the GM, Pacing/Transitions, Intro Page (title, hooks, character cards, transition), and the one-page encounter layout (Approach, Developments, Dramatic Question, Challenge/Social, Character Card links, GM Guidance, Transition). Include guidance for Character Cards themselves.

Success looks like: templates every command will target going forward.

### E5-02. Prompt Refresh for Spec-Kit
Feature description:
Replace the legacy combat/social/exploration/challenge prompts with new prompts that create Arcane Library-friendly specs. Ensure each prompt ties back to the schema definition.

Success looks like: `/speckit.specify` now seeds Arcane Library work instead of pillar encounters.

### E5-03. PDF→Markdown Prompt Revisions
Feature description:
Revise the conversion prompts using findings from Epic 4 so they ask better research questions, cite the two approaches, and capture acceptance criteria for each module type.

Success looks like: future specs bake in the lessons learned from the research phase.

### E5-04. MVP Specification Sweep
Feature description:
Drive a spec that narrows the MVP scope (init scripts + PDF converter + Arcane Library template generation) and sequences work accordingly.

Success looks like: a consensus MVP backlog ready for implementation.

### E5-05. Scenario Conversion Targets
Feature description:
Plan how to convert both Skyhorn Lighthouse scenarios and Temple of the Basilisk Cult to Markdown, including verification steps, schema mapping, and storage locations.

Success looks like: a checklist the team can run for each conversion candidate.

### E5-06. Schema Analysis & Refinement
Feature description:
Create a process where AI analyzes converted scenarios, highlights schema gaps, and proposes revisions to the Arcane Library templates. Include a feedback loop for the GM to accept or adjust.

Success looks like: evolving schemas grounded in real module conversions.



---

## Epic 6 — Version 2 Dungeon & Flow Extensions

### E6-01. V2 Dungeon Room Workflow
Feature description:
Extend the schema to treat each dungeon room as its own encounter page, link map pins to room files, and prompt AI to suggest transitions and clue-routing adjustments. Mention potential Obsidian plugins if relevant.

Success looks like: a ready-to-spec plan for dungeon-heavy adventures once v1 ships.

### E6-02. Clue-Route Diagram Enhancements
Feature description:
Develop a prompt that guides AI through analyzing the clue-route diagram, recommending revisions, and updating the distilled document to reflect those changes using the Arcane Library schema.

Success looks like: consistent transitions and dramatic questions across the entire adventure.

---

These prompts keep planning, specs, and implementation aligned with the Arcane Library direction and the prioritized todo list. Copy the relevant prompt into `/speckit.specify`, attach `planning/project-overview.md`, and iterate through /clarify → /plan → /implement per Spec-Kit conventions.
