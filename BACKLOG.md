# GM-Kit Feature Prompts and Tasks (Arcane Library Edition)

The following epics contain features or tasks.  

- Features are implemented using spec-kit as a formal process.  The verbage for a feature will be used as the initial `/speckit.specify` prompt to translate the feature into executable specs. Prompts are grouped and ordered by those epics so the workflow remains: prompts → specs → plans → tasks → implementation.

- Tasks are items listed in an epic that don't require a formal spec.  These tasks are managed directly by the user instructing the coding assistant and usually involve revisions to the project itself rather than new features.  Examples of tasks are updating user/team documentation, revising context for the coding assistant, restructring project folders and files, some smaller code refactoring, etc. 

---

## ✅ Epic 1 — Repository Setup & Governance **[COMPLETED]**

### ✅ E1-01. Repo Bootstrap (README + .gitignore + Structure Audit) **[FEATURE, COMPLETED]**
Feature description:
Scaffold a minimal README describing GM-Kit’s Arcane Library mission, add a `.gitignore` that excludes `temp-resources/` and `spec-kit/`, and then audit the folder structure and included files to verify the project is ready to push to gihtub. Include instructions for keeping the README synced with planning docs.

Success looks like: a repo that is ready for PRs, ignores transient analysis folders and is ready for python development.

### ✅ E1-02. Development Lifecycle Documentation **[FEATURE, COMPLETED]**
Feature description:
Add contributor documentation that explains the enforced workflow: todos (as epics) → prompts → specs → /plan → tasks → implementation → validation. Highlight how prompts are stored, how specs reference planning artifacts, and where status lives. Include guidance for capturing decisions in Obsidian and syncing back.

Success looks like: anyone can trace a shipped change back to the originating todo epic.

### ⚠️ E1-03. Testing Strategy (Deferred) **[FEATURE, DEFERRED]**
Feature description:
Define how to unit or integration test the MCP. Cover minimal walking tests (CLI dry runs, mock agents) and outline where automated scripts live. Specify pass/fail gates that block shipping (e.g., failing CLI smoke test).

Success looks like: a practical testing rubric the team can run locally before each PR.

## Epic 2 — Development Environment & Walking Skeleton

### ✅ E2-01. Knowledge-Graph MCP Experiment (Optional) **[FEATURE, COMPLETED]**
Feature description:
Spec an experiment that wires a knowledge-graph MCP into the workflow to compare against vendor-provided session distillers. Outline evaluation metrics and fallback plans if the integration adds friction.

Success looks like: documented learnings on whether the knowledge graph improves Arcane Library outputs.

NOTE: The developer will install the mcp and configure it. Use the context at this link in both codex and opencode to ensure it's working correctly: https://github.com/modelcontextprotocol/servers/tree/main/src/memory (See SYSTEM PROMPT section in the readme, note we are using Cheezy's recommended knowledge graph mcp rather than the Memory mcp)

### E2-02. Installation and Walking Skeleton **[FEATURE, COMPLETED as specs/002-installer-skeleton/spec.md]**
Feature description:
1) Deliver a Python/uv installer that installs the following three artifacts:

For macOS/Linux (using $HOME):
    a) Create and populate the $HOME/.local/share/uv/tools/gmkit-cli/lib/python*/site-packages/gmkit_cli/ subfolder. The gmkit_cli subfolder is a package directory with __init__.py and other modules, not a single .py file.
    b) Install ```gmkit``` python file (without the .py extension) to ```$HOME/.local/share/uv/tools/gmkit-cli/bin/gmkit```. This is a short python file (with shebang, no .py extension) that wraps the logic in $HOME/.local/share/uv/tools/gmkit-cli/lib/python*/site-packages/gmkit_cli/.
    c) Create a symlink in $HOME/.local/bin/gmkit that points to ```gmkit``` under ```$HOME/.local/share/uv/tools/gmkit-cli/bin/gmkit```.
        ```$HOME/.local/bin/gmkit -> $HOME/.local/share/uv/tools/gmkit-cli/bin/gmkit```
        i.  This allows the command to be invoked from anywhere as $HOME/.local/bin is included in the OS PATH.

For Windows, mirror the same artifacts in uv’s tool layout:
    a) Create and populate %LOCALAPPDATA%\uv\tools\gmkit-cli\Lib\site-packages\gmkit_cli\ (package directory with __init__.py and other modules).
    b) Install the entrypoint to %LOCALAPPDATA%\uv\tools\gmkit-cli\Scripts\gmkit.exe (or gmkit shim if uv emits one without extension); this wraps the logic in the Lib\site-packages\gmkit_cli\ folder. This .exe is generated by uv when the tool is installed.
    c) Create a shim at %USERPROFILE%\.local\bin\gmkit.cmd (preferred) that forwards to %LOCALAPPDATA%\uv\tools\gmkit-cli\Scripts\gmkit.exe, ensuring %USERPROFILE%\.local\bin is on PATH. If symlinks are available, a symlink is acceptable; if PowerShell is preferred, use gmkit.ps1. If the environment prefers WindowsApps or another PATH location, note that alternative but default to %USERPROFILE%\.local\bin.
        ```%USERPROFILE%\.local\bin\gmkit.cmd -> %LOCALAPPDATA%\uv\tools\gmkit-cli\Scripts\gmkit.exe```
        Example gmkit.cmd contents:
        ```bat
        @echo off
        "%LOCALAPPDATA%\uv\tools\gmkit-cli\Scripts\gmkit.exe" %*
        ```

2) This allows the user to invoke the python "gmkit" command (from a terminal) along with a subcommand "init" which takes three inputs: a) required path to temp folder for writing scripts/prompts, b) optional coding agent type (claude, codex-cli, gemini, qwen), c) optional target OS (windows for PowerShell or macos/linux for bash). If optional parameters are not provided, the Python script prompts the user to select them.

This will install the following folders and logic into the project folder (based on the OS and coding agent selected):

    - <project folder>/<agent folder>/prompts/ (or commands/, or similar): 
        - each coding agent has a different location for the prompts:
            - for claude the location is ```<project folder>/.claude/command```
            - for codex-cli the location is ```<project folder>/.codex-cli/prompts```
            - for gemini the location is ```<project folder>/.gemini/command```
            - for qwen the location is ```<project folder>/.qwen/prompts```
        - the prompt files: are the specific slash commands invoked inside the coding agent.  The first and only prompt markdown file installed by ```gmkit init``` for this feature is:
            - gmkit.hello-gmkit.md
    - <project folder>/.gmkit/memory/  (use `.gmkit` consistently across platforms)
        - constitution.md (contains the core principles the agent is supposed follow when creating TTRPG game master artifacts).
    - <project folder>/.gmkit/scripts/<bash or ps>/ (invoked by the agent on behalf of the /slash command/prompts listed above). 
        - say-hello.sh
    <project folder>/.gmkit/templates (simple template files that are populated with the arguments provided by the script files above).
        - hello-gmkit-template.md

3) Once the project folder has been initialized, the user can then launch his agent of choice and issue the /gmkit.hello-gmkit slash command, passing in a greeting such as "Hello from <Agent>!". This will cause the agent to read and act on behalf of the gmkit.hello-gmkit.md prompt content along with any user provided greeting. This will trigger the following events:
    - The agent will follow the instructions in the gmkit.hello-gmkit.md file to generate the argument list required to invoke the say-hello.sh file passing in the greeting from the user along with a greeting file sequence number.  The agent should determine the latest sequence number by evaluating the "<project folder>/greetings/greetingXX.md" files and looking for the highest sequence number and then incrementing that number by 1.
    - The script execution will fill in the template, replacing variables in the template with the argument list (in this case the single greeting message argument and the sequence number).
    - The script will write the contents of the greeting to the chat window and also write the contents to the markdown file path as "<project folder>/greetings/greetingXX.md", where XX is the numeric sequence number argument.

Non-functional requirements (must be explicit in spec):
    - gmkit init is safe to re-run and idempotent for existing folders/files (no destructive overwrites without clear user intent).
    - Script/template output is deterministic for the same inputs.
    - Clear, actionable error messages for missing paths/permissions.
    - No network access required after installation for hello-gmkit flow.

Out of scope (must be explicit in spec):
    - No real content generation beyond the minimal hello-gmkit scaffolding.
    - hello-gmkit is a temporary walking-skeleton command and will be removed once real commands exist.

Documentation must cover (include in spec and docs):
    - How a new slash command maps to its prompt/script/template artifacts and output path.
    - Campaign flow example: `/gmkit.campaign` installs prompt + script + template, and creates `<project folder>/campaigns/<campaign_name>/campaign_notes.md`.
    - Scenario flow example: `/gmkit.scenario` creates `<project folder>/campaigns/<campaign_name>/scenarios/<scenario_name>/scenario_notes.md`.
    - Two creation patterns: (1) create new folder/file outputs, (2) append a new section inside an existing notes file (e.g., `/gmkit.npc`, `/gmkit.encounter`, `/gmkit.reward` inside scenario notes).
    - Users can create multiple campaigns per project and multiple scenarios per campaign.

Success looks like: 

- contributors can install once with uv,
    - proven by integration tests that will 1) remove the gmkit-cli installation (if it's there) and then install it cleanly. The test will then verify the essential folders and files are present in the installation folder.
- contributors can run "gmkit init" from terminal (with required temp path and optional agent/OS params) have scripts/prompts copied to temp workspace for /gmkit.hello-gmkit
    - proven by tests verifying files in temp workspace, plus documentation on extending the skeleton.
- contributors can invoke /gmkit.hello-gmkit slash command from their coding agent of choice (selected during "gmkit init" command) and the "<project folder>/greetings/greetingXX.md" file will be written with the appropriate XX sequence number.
    - proven by tests that invoke the script directly to fill the template and verify the "<project folder>/greetings/greetingXX.md" file has been written. Agent CLI batch mode is currently non-viable (codex-cli, gemini, opencode) for clean slash-command invocation; codex output is not reliable for automated tests.

### E2-03. CI Pipeline for Walking Skeleton **[FEATURE, COMPLETED as specs/001-ci-walking-skeleton/spec.md]**
Feature description:
Establish a CI pipeline that validates the walking skeleton implementation (E2-02). The pipeline must run quality gates including lint/format/type-check, unit tests for installer functionality, and integration tests for the gmkit init and hello-gmkit workflows. CI is Linux-only; Windows validation is deferred to CD.

Requirements:
- Unit tests covering installer components (folder creation, script generation, symlink creation)
- Integration tests for `gmkit init` command across supported agents (claude, codex-cli, gemini, qwen)
- Integration tests for `/gmkit.hello-gmkit` workflows run scripts directly to render templates (no agent invocation)
- Linux parity tests compare bash and PowerShell outputs using pwsh on Linux; CI fails if pwsh cannot be installed
- Pipeline runs on each PR to master branch

Success looks like: a passing Linux CI pipeline that validates the walking skeleton functionality, including parity checks and script-rendered outputs.

### E2-04. Constitution Guardrails Template (Licensed Content + Unsafe Behavior)
Feature description:
Add licensed‑content and unsafe‑behavior guardrails to the default `constitution.md` template shipped with GM‑Kit. Ensure `gmkit init` scaffolding copies this template into `.gmkit/memory/constitution.md` so every project starts with these guardrails baked in. Cross‑platform CLI compatibility is already addressed in E2-02 and is out of scope here.

Success looks like: `gmkit init` installs `.gmkit/memory/constitution.md` from a template that explicitly states the licensed‑content and unsafe‑behavior guardrails the agent must follow.

Sync: quickstart synced to docs/user/user_guide.md; plan/research/data-model synced to ARCHITECTURE.md; mark **SYNCED**

### E2-05. PDF Safety Scanner (Optional)
Feature description:
Add an optional PDF safety scanner that checks for suspicious elements before processing. Uses `pdfid` library to detect red flags such as embedded JavaScript, Launch actions, embedded files, and automatic open actions. This is a precautionary feature—RPG PDFs from legitimate publishers are extremely unlikely to contain malicious content—but provides peace of mind for users processing PDFs from less trusted sources.

Scope:
- Integrate `pdfid` as an optional dependency
- Provide a `gmkit scan <pdf-path>` command that reports concerns
- Optionally integrate into PDF conversion workflow with `--scan` flag
- Clear user-facing warnings that distinguish high-risk indicators (Launch, JS) from low-risk (AcroForm)

Out of scope:
- Deep malware analysis or signature-based detection
- Blocking/quarantining files (user decides how to proceed)

Success looks like: Users can run `gmkit scan module.pdf` and receive a clear report of any suspicious indicators, or "No concerns found" for clean files.

Priority: LOW (MVP does not require this; add if user feedback indicates demand)

### E2-06. Remove Walking Skeleton Placeholder Command **[TASK]**
Task description:
Remove the `/gmkit.hello-gmkit` command and associated bash/PowerShell scripts once the first official command (`/gmkit.pdf-to-markdown`) is implemented. The hello-gmkit command was a placeholder for the walking skeleton CI implementation and is no longer needed.

Scope:
- Remove `say-hello.sh` and `say-hello.ps1` from `src/gm_kit/assets/scripts/`
- Remove `hello-gmkit-template.md` from `src/gm_kit/assets/templates/`
- Remove `gmkit.hello-gmkit.md` prompt file from assets
- Update `gmkit init` to no longer install hello-gmkit artifacts
- Update CI parity tests to use pdf-convert instead of hello-gmkit
- Update documentation (user_guide.md, ARCHITECTURE.md)

Success looks like: The walking skeleton placeholder is cleanly removed with no orphaned files or documentation references.

Depends on: E4-07e (PDF conversion orchestration) must be implemented first.

### E2-07. Research: Replace Bash/PowerShell with Python for Agent Scripts **[TASK]**
Task description:
Research and document whether to replace all bash/PowerShell agent-invoked scripts with Python implementations. The original spec-kit design used bash/PowerShell because it needed to create git branches. GM-Kit has no git dependency (version control is out of scope), so Python can handle all operations directly.

Background:
- Python is already installed (UV requirement)
- Python can be invoked via `#!/usr/bin/env python3` shebang
- Eliminates need for cross-platform script parity testing
- Simplifies the codebase (one language instead of three)

Scope:
1. Document decision rationale in `docs/team/spec-kit-analysis/Spec-Kit-Analysis.md` (add note that gm-kit deprecates bash/ps in favor of Python-only implementation)
2. Update `docs/user/user_guide.md` to reflect Python-only approach
3. Update `ARCHITECTURE.md` to remove bash/PowerShell parity references
4. Add note that bash/PowerShell can be re-implemented in future if a specific need is discovered

Success looks like: Clear documentation of the Python-only decision with rationale, and updated docs reflecting the simplified architecture.

Timing: Complete after E2-06 (hello-gmkit removal) and E4-07e implementation.

### E2-08. Multi-Agent CI Testing (Optional) **[FEATURE]**
Feature description:
Add optional CI/CD tests that verify slash commands work correctly when invoked through actual AI agents. This validates the end-to-end flow from slash command → agent → CLI → output.

Implementation approach:
1. **Phase 1 (POC):** Implement Gemini agent testing only (free tier available)
   - Install Gemini CLI in GitHub Actions
   - Authenticate using secrets
   - Invoke `/gmkit.pdf-to-markdown` with test PDF
   - Verify expected output files are created
2. **Phase 2:** Expand to other agents (Claude, Codex, Qwen) as separate tasks
3. **Cost control:** Tests enabled/disabled via `RUN_AGENT_TESTS` environment variable
   - Default: disabled (to avoid unexpected API costs)
   - Can be scheduled on less frequent basis (weekly vs per-PR)

Requirements:
- Environment variable toggle (`RUN_AGENT_TESTS=true` to enable)
- Graceful skip when disabled (not a failure)
- Clear cost documentation for each agent
- Secrets management for API keys

Success looks like: Optional CI job that validates slash command → agent → CLI flow works correctly, with Gemini as the initial proof of concept.

Priority: LOW (nice-to-have after core features are stable)

---

## Epic 3 — Spec-Kit Architecture Analysis

### ✅ E3-01. Spec-Kit Repo Deep Dive **[FEATURE, COMPLETED as docs/team/spec-kit-analysis/Spec-Kit-Analysis.md]**
Feature description:
Download the upstream spec-kit repo and catalogue how commands, templates, and scripts are organized. Include notes on versioning, template prefixes, and how prompts feed specs.

Success looks like: a concise reference document file stored as `docs/team/spec-kit-analysis/Spec-Kit-Analysis.md` that captures the structural learnings.

### ✅ E3-02. Constitution → Gate Mapping **[FEATURE, COMPLETED as docs/team/spec-kit-analysis/docs/spec-driven.md]**
Feature description:
Trace how Spec-Kit’s constitution articles produce gates like the “Simplicity Gate” and “Anti-Abstraction Gate.” Clarify what “No future-proofing” truly enforces and how those checks can be adapted for GM-Kit.

Success looks like: actionable guidance for crafting GM-Kit checklists based on upstream doctrine.

JTG 01-23-2025 There are two questions that went unanswered during investigation regarding the gates above:
    - Where do these concepts originate from spec-kit? We only see explanations in spec-kit’s spec-driven.md documentation file.
    - How are the simplicity and abstraction gates included in the /plan's pre check list? 

### ✅ E3-03. Spec-Kit Command Flow (Specify-Only) **[FEATURE, COMPLETED as docs/team/spec-kit-analysis/Spec-Kit-Analysis.md]**
Feature description:
Document the `/speckit.specify` flow only: how the command, script, and templates interact to produce `spec.md` and `requirements.md` in a new feature folder.

Success looks like: a clear walkthrough of the specify command’s inputs/outputs and how placeholder rendering happens in practice.

---

## Epic 4 — PDF → Markdown Research & Pipelines

### ✅ E4-01. Research Plan Across Three Module Formats **[COMPLETED]**
Feature description:
Define the research matrix and evaluation set. Current test PDFs:
- `temp-resources/Dungeon Module B2, The Keep on the Borderlands.pdf` (2‑column, dense, maps/tables)
- `temp-resources/Temple of the Basilisk Cult Print Friendly V9.pdf` (outline/bulleted)
- `temp-resources/CHA23131 Call of Cthulhu 7th Edition Quick-Start Rules.pdf` (modern layout)
- `temp-resources/Werewolf_The_Apocalypse_No_Matter_How_Small.pdf` (complex typography/backgrounds)
- `temp-resources/The Homebrewery - NaturalCrit.pdf` (short, standard D&D formatting)
- `temp-resources/JG102 The Caverns of Thracia.pdf` (scanned, single‑column; out of scope—use external tools)
- `temp-resources/tsr09067 - M1 Blizzard Pass.pdf` (scanned, double‑column, bleed‑through; out of scope—use external tools)

Outline success criteria, manual review steps, and how findings will be recorded.

Success looks like: a reproducible study plan plus concrete guidance to include in the E4-07 `/specify` prompt and acceptance criteria, with success criteria covering:
- Structural accuracy (heading levels, section boundaries)
- Callout fidelity (boxed text preserved as blockquotes, read‑aloud vs GM notes tagged)
- Content completeness (no missing sections/paragraphs/tables)
- Layout sanity (correct column order, no header/footer noise)
- Cleanup effort (time and number of manual edits)
- Column gutter spacing artifacts removed (extra spaces from 2‑column alignment)
- End‑of‑line hyphenation artifacts fixed

Manual review steps (fixed checklist for each PDF):
- Verify heading hierarchy (H1/H2/H3) against the source
- Confirm section order and column reading order
- Check boxed text/callouts formatting and placement
- Spot-check tables and lists for completeness
- Identify gutter spacing artifacts and hyphenation errors
- Estimate cleanup time and log edit counts

Findings recorded in: `specs/004-pdf-research/findings/` (one file per PDF, plus summaries as needed).

**Research matrix (completed):**
| Agent | Keep on the Borderlands | Call of Cthulhu |
|-------|-------------------------|-----------------|
| Claude | Tested | Tested |
| Codex | Tested | Tested |
| Gemini | Tested | Tested |
| Qwen | Tested | Tested |

**Outputs:**
- `specs/004-pdf-research/findings/keep-on-the-borderlands.md`
- `specs/004-pdf-research/findings/call-of-cthulhu.md`
- `specs/004-pdf-research/findings/call-of-cthulhu-codex-report.md` (detailed Codex conversion report)
- `specs/004-pdf-research/findings/review-checklist.md`
- `specs/004-pdf-research/pdf-conversion-architecture.md` (63-step pipeline derived from research)

**Deferred to E4-07a/b/c:** Testing of Temple of the Basilisk Cult, Werewolf, and The Homebrewery PDFs during implementation validation.

### ✅ E4-02. AI-Only Conversion Approach **[COMPLETED]**
Feature description:
Prompt AI to perform direct conversion of PDFs into Markdown, documenting the end-to-end steps being evaluated:
1) ingest/validate PDF, 2) optional pre-process (deskew/chunk), 3) extract text + structure cues,
4) detect hierarchy, 5) convert to Markdown, 6) handle boxed text/callouts,
7) normalize/clean, 8) image extraction approach (research only), 9) QA/verification pass,
10) iterate/repair, 11) finalize output.
OCR for image-only PDFs is out of scope; direct users to external tools.

Success looks like: documented AI-only steps and checks plus a comparison against the CLI/Python pipeline, resulting in a recommendation (or hybrid split) to be embedded in the E4-07 `/specify` prompt.

**Outcome:** AI-only approach is too costly due to API usage limits and token consumption for large PDFs. A hybrid approach combining Code (for deterministic preprocessing/cleanup), Agent (for judgment calls), and User (for confirmation) saves AI usage and produces more consistent results. This hybrid approach is captured in the 63-step architecture with category pyramid: Code (43 steps) > Agent (15 steps) > User (5 steps).

**Reference:** `specs/004-pdf-research/pdf-conversion-architecture.md`

### ✅ E4-03. CLI/Python Conversion Pipeline **[COMPLETED]**
Feature description:
Design the hybrid workflow (CLI utilities vs pure-Python alternatives) and document the end-to-end steps being evaluated:
1) ingest/validate PDF, 2) optional pre-process (deskew/chunk), 3) extract text + structure cues,
4) detect hierarchy, 5) convert to Markdown, 6) handle boxed text/callouts,
7) normalize/clean, 8) image extraction approach (research only), 9) QA/verification pass,
10) iterate/repair, 11) finalize output.
OCR for image-only PDFs is out of scope; direct users to external tools.
Include install guidance for Windows/macOS/Linux and show where AI should clean up the Markdown output.

Success looks like: a spec-ready CLI/Python blueprint plus a comparison against the AI-only approach, resulting in a recommendation (or hybrid split) to be embedded in the E4-07 `/specify` prompt.

**Recommendation (from findings):** Use a hybrid approach combining Code, Agent, and User intervention:
- **Code (PyMuPDF):** Preprocessing (image extraction, image removal, TOC extraction, font sampling), deterministic cleanup (character-level fixes, word-level fixes), structural detection, and report generation. Pure Python avoids per-OS CLI dependencies.
- **Agent:** Judgment calls requiring context (visual TOC parsing, spelling correction, table detection/conversion, quality assessments, two-column reading order validation).
- **User:** Confirmation steps for font-family labels, header/footer removal, and final issue resolution.

CLI text extraction tools (pdftotext, etc.) were tested but found unreliable for two-column PDFs. PyMuPDF provides consistent cross-platform results for preprocessing while Agent handles text extraction and judgment calls.

**Reference:**
- `specs/004-pdf-research/findings/keep-on-the-borderlands.md`
- `specs/004-pdf-research/pdf-conversion-architecture.md`

### ✅ E4-04. Heading & Hierarchy Verification Tooling **[COMPLETED]**
Feature description:
Define a process that surfaces title snippets from the PDF, allows the AI/user to assign heading levels, and validates whether the Markdown mirrors the PDF's hierarchy.

Success looks like: heading-validation rules and a QA checklist that can be inserted into the E4-07 `/specify` prompt.

**Outcome:** Heading verification is integrated into the conversion pipeline rather than a standalone command:
- **Phase 3:** Font-family sampling with TOC-based label pre-fill (steps 3.4-3.6)
- **Phase 7:** Build heading map from TOC, detect heading patterns (ALL CAPS, Title Case), detect inline/embedded headings, user reviews font-family labels (steps 7.1-7.4, 7.9-7.11)
- **Phase 8:** Apply heading levels, validate hierarchy has no level skips (steps 8.2-8.3, 8.10-8.11)
- **Phase 9:** Review TOC validation issues (step 9.7)

**Reference:** `specs/004-pdf-research/pdf-conversion-architecture.md`

### ✅ E4-05. Box Text & Callout Handling **[COMPLETED]**
Feature description:
Define how boxed text should appear in Markdown (`>`), how to tag read-aloud vs GM-only notes, and how to preserve their placement relative to body copy.

Success looks like: box-text handling rules formatted as prompt-ready guidance for E4-07.

**Outcome:** Box-text and callout handling is integrated into the conversion pipeline:
- **Phase 7 (Detection):** GM/Keeper note keyword detection (step 7.5), read-aloud text marker detection (step 7.6), quote blocks and attribution detection (step 7.7)
- **Phase 8 (Application):** Apply GM note blockquote formatting (step 8.4), apply read-aloud blockquote formatting (step 8.5), apply quote formatting with italic + attribution (step 8.6), apply blockquote formatting to callout boxes (step 8.8)
- **Phase 9 (Verification):** Callout formatting check (step 9.5)

**Reference:** `specs/004-pdf-research/pdf-conversion-architecture.md`

### ✅ E4-06. Version 2 Image Extraction **[COMPLETED]**
Feature description:
Plan the follow-up feature that extracts images, saves them to `images/`, and injects relative links into the Markdown at the correct positions. Include licensing cautions.

Success looks like: a scoped V2 plan that can follow the initial converter work.

**Outcome:** Image extraction is included in the base pipeline (Phase 1). Injecting visible image links may not always be desired (licensing concerns, user preference), so the approach is to inject **commented-out** image links at the correct positions. This preserves location information while keeping images hidden by default. User or agent can uncomment if desired.

**Example output:**
```markdown
[FIGURE: Map of the dungeon level 1]
<!-- ![Map of the dungeon level 1](images/page005_img01.png) -->
```

**Implementation:** Covered by E4-07d (Image Link Injection feature).

**Reference:** `specs/004-pdf-research/pdf-conversion-architecture.md`

### E4-07a. PDF→Markdown Code-Driven Pipeline **[FEATURE]**

Feature description:

Implement the Code-category steps (49 of 70 total) from the PDF conversion architecture. This includes Python/PyMuPDF modules for image extraction, image removal, TOC extraction, font sampling, text extraction, chunking, merging, character-level fixes, word-level fixes, structural detection, hierarchy application, markdown linting, and report generation.

Architecture reference: `specs/004-pdf-research/pdf-conversion-architecture.md`

Requirements:
- TDD with unit and integration tests for each module
- Modular phase functions that can be composed into a pipeline
- CLI interface for running individual phases or full pipeline
- Phase-by-phase markdown output for diagnostics
- Regression testing: Any anomalies discovered during integration testing that require code changes to a step must be accompanied by new unit tests covering the specific anomaly

Phases covered: 1, 2, most of 3-8, scaffolding for 9-10

Success looks like: A tested Python package that executes all Code-category steps reliably and produces intermediate outputs for each phase.

### E4-07b. PDF→Markdown Agent-Driven Pipeline **[FEATURE]**

Feature description:

Implement the Agent-category steps (15 of 70 total) from the PDF conversion architecture. This includes prompt templates and contracts for visual TOC parsing, sentence boundary resolution, spelling correction, table detection, table conversion, callout formatting, figure placeholders, quality assessments, and two-column reading order validation.

Architecture reference: `specs/004-pdf-research/pdf-conversion-architecture.md`

Requirements:
- Prompt templates for each agent step (15 total): These are AI-directed prompts invoked by the orchestrator at specific steps—not user-facing prompts, not phase-level, and not for the entire command. Each template defines the task, input format, expected output format, and edge cases for a single step.
- Contract definitions (input/output specifications)
- Rubric definitions for evaluation
- Integration points with E4-07a Code pipeline
- Testing via contract testing, rubric evaluation, golden file comparison, structural validation

Steps covered: 3.2, 4.6, 6.4, 7.7, 8.6-8.8, 9.1-9.5, 9.7-9.8, 10.2-10.3

Success looks like: Agent prompts that reliably produce outputs meeting defined contracts and rubrics, integrated with the Code pipeline.

### E4-07c. PDF→Markdown User Interaction Workflow **[FEATURE]**

Feature description:

Implement the User-category steps (5 of 70 total) from the PDF conversion architecture. This includes pre-flight confirmation, interactive prompts for font-family label review, header/footer removal confirmation, and final issue resolution.

Architecture reference: `specs/004-pdf-research/pdf-conversion-architecture.md`

Requirements:
- Pre-flight confirmation prompt (step 0.6) - gates the entire pipeline
- Interactive prompts that present analysis results clearly
- Before/after display for proposed changes
- Smart analysis presentation (e.g., header frequency, multi-per-page detection)
- Correction capture and application
- Integration with E4-07a and E4-07b pipelines

Steps covered: 0.6, 7.10, 9.9-9.11

Design note — Phase 9 review interaction has two candidate flows to evaluate:
1. **Interactive one-at-a-time**: Agent presents each concern individually, collects user response, applies revision, then moves to the next. Tight feedback loop.
2. **Checklist-based batch**: Agent generates `review-checklist.md` with all concerns, user annotates the file (approvals, corrections, notes), then agent processes all annotations in one pass. Better for users who want to review holistically before committing changes.

These flows may coexist: the interactive flow for the default agent-driven path, and the checklist flow as an alternative for users who prefer batch review. The `review-checklist.md` output file could serve double duty — as both the batch-review input artifact and the post-conversion QA record.

Success looks like: User can review agent findings, confirm or correct proposed changes, and have corrections applied to the final output.

### E4-07d. PDF→Markdown Image Link Injection **[FEATURE]**

Feature description:

Implement image position tracking and commented link injection. During image extraction, log image positions (page, coordinates) to a manifest file. During hierarchy application, use the manifest to inject commented-out image links at the correct positions in the markdown. This preserves image location information while keeping images hidden by default.

Architecture reference: `specs/004-pdf-research/pdf-conversion-architecture.md`

Requirements:
- Generate `images/image-manifest.json` during Phase 1 extraction (step 1.4)
- Insert commented image links during Phase 8 hierarchy application (step 8.9)
- Licensing caution documentation for users who uncomment image links, appearing in three locations:
  1. **Conversion report**: A note reminding users that extracted images remain under publisher copyright
  2. **User guide**: A section explaining when it's appropriate to uncomment image links (personal table use: OK; publishing/redistribution: not OK)
  3. **Inline markdown comment**: A licensing notice block inserted near the first image reference in each converted document, using metadata extracted from PDF in step 0.1
- Integration with E4-07a Code pipeline

Steps covered: 1.4, 8.9

Example output:
```markdown
<!--
IMAGE LICENSING NOTE
Images extracted from this PDF are copyrighted by [Author/Publisher from metadata].
They are commented out by default. Uncommenting for personal use at your table
is generally acceptable, but do not redistribute or publish without permission.
-->

[FIGURE: Map of the dungeon level 1]
<!-- ![Map of the dungeon level 1](images/page005_img01.png) -->
```

Success looks like: Images are extracted with position data, commented links appear at correct locations in markdown output, and licensing cautions are present in the conversion report, user guide, and inline in the markdown.

### E4-07e. PDF→Markdown Command Orchestration **[FEATURE]**

Feature description:

Implement the `/gmkit.pdf-to-markdown` slash command and `gmkit pdf-convert` CLI that orchestrates the entire conversion pipeline. This is the top-level feature that integrates E4-07a/b/c/d components.

Architecture reference: `specs/004-pdf-research/pdf-conversion-architecture.md`

Requirements:
- Command prompt file (`gmkit.pdf-to-markdown.md`) defining full conversion flow
- CLI interface with resume/retry capabilities:
  - `gmkit pdf-convert <pdf-path> --output <dir>` - Full pipeline
  - `gmkit pdf-convert --resume <dir>` - Resume from checkpoint
  - `gmkit pdf-convert --phase N <dir>` - Re-run specific phase
  - `gmkit pdf-convert --from-step N.N <dir>` - Re-run from specific step
  - `gmkit pdf-convert --status <dir>` - Check progress
- Pre-flight analysis (Phase 0) with complexity report
- State tracking (`.state.json`) for progress and resumability
- User involvement notices at start (list phases requiring input)
- Integration orchestration for E4-07a/b/c/d components (initially with stubs)
- Copyright notice block at top of final markdown output warning users about text reproduction. Uses metadata extracted from PDF in step 0.1 (title, author, publisher, copyright if available):
  ```markdown
  <!--
  COPYRIGHT NOTICE
  ================
  This markdown file was converted from a copyrighted PDF for personal game
  preparation use only. The text, structure, and content remain the intellectual
  property of the original publisher. Do not redistribute, publish, or share
  this file publicly. For official content, please purchase from the publisher.

  Title: [PDF title metadata or filename]
  Author/Publisher: [PDF author/creator metadata if available]
  Copyright: [PDF copyright metadata if available]
  Source file: [Original PDF filename]
  Converted: [Date]
  Tool: GM-Kit pdf-convert
  -->
  ```

Implementation approach (top-down):
1. Implement E4-07e first with stubs/mocks for a/b/c/d
2. Then implement E4-07a (Code pipeline) replacing stubs
3. Then implement E4-07b (Agent pipeline) replacing stubs
4. Then implement E4-07c (User interaction) replacing stubs
5. Then implement E4-07d (Image link injection) replacing stubs

Steps covered: 0.1-0.5 (Pre-flight Analysis code steps), orchestration of all phases. Note: Step 0.6 (user confirmation) is owned by E4-07c; E4-07e calls into E4-07c for that interaction.

Entry points:
- `/gmkit.pdf-to-markdown` slash command (prompt file that invokes CLI)
- `gmkit pdf-convert` CLI (direct invocation)

Testing approach:
- Integration tests use mocks for Code steps (Python), Agent steps (prompts), and User steps (pexpect)
- Unit tests retain mocks permanently for isolation
- Mocks replaced by real implementations when E4-07a/b/c/d are complete

Success looks like: User can invoke `/gmkit.pdf-to-markdown` with a PDF path, see a pre-flight complexity report, confirm to proceed, and have the pipeline execute with proper state tracking and resumability.

### E4-08. Workspace-Level Active Conversion Tracking **[FEATURE]**

Feature description:

Store the active conversion directory in `.gmkit/active-conversion.json` so that `--resume`, `--phase`, `--from-step`, and `--status` can infer the target directory without the user specifying it explicitly. Similar to how spec-kit tracks the active feature folder.

Requirements:
- When a new conversion starts, write the output directory path to `.gmkit/active-conversion.json`
- `gmkit pdf-convert --resume` (no path) reads from active conversion state
- `gmkit pdf-convert --phase N` (no path) reads from active conversion state
- `gmkit pdf-convert --from-step N.N` (no path) reads from active conversion state
- `gmkit pdf-convert --status` (no path) reads from active conversion state
- Handle multiple conversions: decide whether to track only the most recent, or support multiple with a selection prompt
- Handle stale references: if the tracked directory was deleted or moved, show a clear error
- Explicit path always overrides the inferred path

Dependencies: E4-07e (command orchestration must be complete)

Success looks like: User can run `gmkit pdf-convert my-module.pdf`, then later run `gmkit pdf-convert --resume` without specifying the directory, and it resumes the correct conversion.

### E4-09. Font Size/Weight/Style in Heading-Level Inference **[INVESTIGATION]**

Feature description:

Evaluate whether font size, weight, and style variants (not just family name) are needed for accurate heading-level inference during Phase 7 (Font Label Assignment) and Phase 8 (Heading Insertion). Currently FR-015 uses base font name only. The spec notes this may need revision after testing with real PDFs.

Requirements:
- Test heading inference with real RPG PDFs using family name only vs. family+size+weight+style
- Determine if size/weight/style improves heading-level accuracy (e.g., distinguishing `Arial 18pt Bold` as h1 from `Arial 12pt Regular` as body)

### E4-10. Ruff Ruleset Expansion + Refactor Checks **[FEATURE, COMPLETED]**

Feature description:
Enable a focused Ruff ruleset for the CLI codebase (E/W/F/I/B/UP/SIM + PLR), and address any new lint findings. Keep security scanning in Bandit rather than enabling Ruff security rules.

Requirements:
- Configure `pyproject.toml` Ruff rule selection for the focused set plus refactor rules (`PLR`).
- Run `just lint` and fix all exposed issues.

Success looks like: Ruff lint passes with the expanded ruleset and no new lint errors.
- If needed, update `metadata.py` to extract and store font size/weight/style in the font family data
- Update FR-015 in spec.md based on findings
- Update `font-family-mapping.json` schema if additional font attributes are tracked

Dependencies: E4-07a (code-driven pipeline must be functional to test with real PDFs)

Success looks like: A documented decision on whether font attributes beyond family name are needed, with metadata.py and the spec updated accordingly.

---

## Epic 5 — Prompt & Schema Overhaul (Arcane Library)

### E5-01. Arcane Library Schema Definition
Feature description:
Spec the authoritative schema for Synopsis, Background, Word to the GM, Pacing/Transitions, Intro Page (title, hooks, character cards, transition), and the one-page encounter layout (Approach, Developments, Dramatic Question, Challenge/Social, Character Card links, GM Guidance, Transition). Include guidance for Character Cards themselves.

Success looks like: templates every command will target going forward.

### E5-02. Prompt Refresh for Spec-Kit
Feature description:
Replace the legacy combat/social/exploration/challenge prompts with new prompts that create Arcane Library-friendly specs. Ensure each prompt ties back to the schema definition.

Success looks like: `/speckit.specify` now seeds Arcane Library work instead of pillar encounters.

### E5-03. PDF→Markdown Prompt Revisions
Feature description:
Revise the conversion prompts using findings from Epic 4 so they ask better research questions, cite the two approaches, and capture acceptance criteria for each module type.

Success looks like: future specs bake in the lessons learned from the research phase.

### E5-04. MVP Specification Sweep
Feature description:
Drive a spec that narrows the MVP scope (init scripts + PDF converter + Arcane Library template generation) and sequences work accordingly.

Success looks like: a consensus MVP backlog ready for implementation.

### E5-05. Scenario Conversion Targets
Feature description:
Plan how to convert both Skyhorn Lighthouse scenarios and Temple of the Basilisk Cult to Markdown, including verification steps, schema mapping, and storage locations.

Success looks like: a checklist the team can run for each conversion candidate.

### E5-06. Schema Analysis & Refinement
Feature description:
Create a process where AI analyzes converted scenarios, highlights schema gaps, and proposes revisions to the Arcane Library templates. Include a feedback loop for the GM to accept or adjust.

Success looks like: evolving schemas grounded in real module conversions.



---

## Epic 6 — Version 2 Dungeon & Flow Extensions

### E6-01. V2 Dungeon Room Workflow
Feature description:
Extend the schema to treat each dungeon room as its own encounter page, link map pins to room files, and prompt AI to suggest transitions and clue-routing adjustments. Mention potential Obsidian plugins if relevant.

Success looks like: a ready-to-spec plan for dungeon-heavy adventures once v1 ships.

### E6-02. Clue-Route Diagram Enhancements
Feature description:
Develop a prompt that guides AI through analyzing the clue-route diagram, recommending revisions, and updating the distilled document to reflect those changes using the Arcane Library schema.

Success looks like: consistent transitions and dramatic questions across the entire adventure.

---

These prompts keep planning, specs, and implementation aligned with the Arcane Library direction and the prioritized todo list. Copy the relevant prompt into `/speckit.specify`, attach `docs/teams/project-overview.md`, and iterate through /clarify → /plan → /implement per Spec-Kit conventions.
